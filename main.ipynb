{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import time\n",
    "import sqlalchemy as alch\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\augus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.read_csv('Barcelona_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MY_APY_KEY = os.getenv('API_KEY')\n",
    "payload={}\n",
    "headers = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping with Google Maps API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all Restaurants in Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_req(i, radius, API_KEY, total_req):\n",
    "    \"\"\"\n",
    "    Sends a normalized request to the Google Places API to search for nearby restaurants based on the provided location and radius.\n",
    "\n",
    "    Args:\n",
    "        i (str): The location coordinates in the format \"latitude%2Clongitude\".\n",
    "        radius (int): The radius (in meters) within which to search for restaurants.\n",
    "        API_KEY (str): The API key to access the Google Places API.\n",
    "        total_req (int): The total number of requests made so far.\n",
    "\n",
    "    Returns:\n",
    "        requests.Response: The response object containing the result of the API request.\n",
    "    \"\"\"\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={i}&radius={radius}&type=restaurantes&keyword=restaurant&key={API_KEY}\"\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    total_req += 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_page_req(response, APY_KEY, total_req):\n",
    "    \"\"\"\n",
    "    Sends a request to the Google Places API to retrieve the next page of results based on the provided response object. The previous request\n",
    "    can return up to 60 results, organized in 3 pages with 20 results each. If that is the case, the previous request will contain the argument\n",
    "    'next_page_toke'. If not, this argument will not be on the resposne\n",
    "\n",
    "    Args:\n",
    "        response (requests.Response): The response object from the previous API request.\n",
    "        API_KEY (str): The API key to access the Google Places API.\n",
    "        total_req (int): The total number of requests made so far.\n",
    "\n",
    "    Returns:\n",
    "        requests.Response: The response object containing the result of the API request for the next page.\n",
    "    \"\"\"\n",
    "    time.sleep(5)\n",
    "    next_page = response.json()['next_page_token']\n",
    "    url = f'https://maps.googleapis.com/maps/api/place/nearbysearch/json?pagetoken={next_page}&key={APY_KEY}'\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    total_req += 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appending_responses(response, business_type, location, name, place_id, raiting, price_level, user_raitings_total, vicinity):\n",
    "    \"\"\"\n",
    "    Extracts specific information from the response object and appends it to the corresponding lists.\n",
    "\n",
    "    Args:\n",
    "        response (requests.Response): The response object from the API request.\n",
    "        business_type (list): The list to store the business status of each result.\n",
    "        location (list): The list to store the location of each result.\n",
    "        name (list): The list to store the name of each result.\n",
    "        place_id (list): The list to store the place ID of each result.\n",
    "        rating (list): The list to store the rating of each result.\n",
    "        price_level (list): The list to store the price level of each result.\n",
    "        user_ratings_total (list): The list to store the total number of user ratings for each result.\n",
    "        vicinity (list): The list to store the vicinity (address or neighborhood) of each result.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated lists of business_type, location, name, place_id, rating,\n",
    "               price_level, user_ratings_total, and vicinity.\n",
    "    \"\"\"\n",
    "    for i in response.json()['results']:\n",
    "        try:\n",
    "            business_type.append(i['business_status'])\n",
    "        except KeyError:\n",
    "            business_type.append(np.nan)\n",
    "        try:\n",
    "            location.append(i['geometry']['location'])\n",
    "        except KeyError:\n",
    "            location.append(np.nan)\n",
    "        try:\n",
    "            name.append(i['name'])\n",
    "        except KeyError:\n",
    "            name.append(np.nan)\n",
    "        try:\n",
    "            place_id.append(i['place_id'])\n",
    "        except KeyError:\n",
    "            place_id.append(np.nan)\n",
    "        try:\n",
    "            raiting.append(i['rating'])\n",
    "        except KeyError:\n",
    "            raiting.append(np.nan)\n",
    "        try:\n",
    "            price_level.append(i['price_level'])\n",
    "        except KeyError:\n",
    "            price_level.append(np.nan)\n",
    "        try:\n",
    "            user_raitings_total.append(i['user_ratings_total'])\n",
    "        except KeyError:\n",
    "            user_raitings_total.append(np.nan)\n",
    "        try:\n",
    "            vicinity.append(i['vicinity'])\n",
    "        except:\n",
    "            vicinity.append(np.nan)\n",
    "    return business_type, location, name, place_id, raiting, price_level, user_raitings_total, vicinity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 50\n",
    "total_req = 0\n",
    "\n",
    "business_type = []\n",
    "location = []\n",
    "name = []\n",
    "place_id = []\n",
    "raiting = []\n",
    "price_level = []\n",
    "user_raitings_total = []\n",
    "vicinity = []\n",
    "total_req = 0\n",
    "\n",
    "for j in coordinates.columns[:1]:\n",
    "    for i in coordinates[j][:2]:\n",
    "        response = norm_req(i, radius, MY_APY_KEY, total_req)\n",
    "        appending_responses(response)\n",
    "        try:\n",
    "            response = next_page_req(response, MY_APY_KEY, total_req)\n",
    "            appending_responses(response)\n",
    "            try:\n",
    "                response = next_page_req(response, MY_APY_KEY, total_req)\n",
    "                appending_responses(response)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {\n",
    "    'name': name,\n",
    "    'place_id': place_id,\n",
    "    'business_status': business_type,\n",
    "    'location': location,\n",
    "    'raiting': raiting,\n",
    "    'price_level': price_level,\n",
    "    'total_reviews': user_raitings_total,\n",
    "    'direction': vicinity\n",
    "}\n",
    "my_data = pd.DataFrame(my_data)\n",
    "\n",
    "my_data = my_data.drop_duplicates(subset=['place_id', 'location']) # Dropping same restaurant in case I scrapped twice\n",
    "my_data['latitud'] = my_data['location'].apply(lambda x: x.split(\",\")[0].split(\":\")[1].strip()) #Isolating the latitud\n",
    "my_data['longitud'] = my_data['location'].apply(lambda x: x.split(\",\")[1].split(\":\")[1].strip()[:-1]) #Isolating the longitud\n",
    "my_data.drop(columns='location', inplace=True)\n",
    "\n",
    "my_data.to_csv('barc_restaurants.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the neightbourhood of each restaurant (using Mongo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client[\"Search_Restaurants\"]\n",
    "df_distritos = db.get_collection(\"Distritos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client[\"Search_Restaurants\"]\n",
    "df_barrios = db.get_collection(\"Neightbours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barrios(df, long, lat):\n",
    "    \"\"\"\n",
    "    Retrieves the name of the neighborhood (barrio) that intersects with the specified coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - lat (float): Latitude of the location.\n",
    "    - long (float): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    - str: The name of the neighborhood (barrio) that intersects with the specified coordinates.\n",
    "           If no intersection is found, it returns \"Not found\".\n",
    "    \"\"\"\n",
    "    my_position = {\"type\": \"Point\", \"coordinates\": [long, lat]} # o al revés\n",
    "\n",
    "    result = df.find_one(\n",
    "            {\"geometry\": \n",
    "                    {\"$geoIntersects\": \n",
    "                        {\"$geometry\": my_position}}\n",
    "            })\n",
    "    try:\n",
    "        return result[\"properties\"][\"NOM\"]\n",
    "    except:\n",
    "        return \"Not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['neightbour'] = my_data.apply(lambda row: get_barrios(df_barrios, row['longitud'], row['latitud']), axis=1)\n",
    "my_data['distritos'] = my_data.apply(lambda row: get_barrios(df_distritos, row['longitud'], row['latitud']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.to_csv('barc_restaurants.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reviews details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv('barc_restaurants.csv')\n",
    "place_reviews = {'place_id':[], 'reviews': [], 'reviews_rating': [], 'time': []}\n",
    "\n",
    "count_yes = 0\n",
    "count_no = 0\n",
    "n = 0\n",
    "for i in restaurants['place_id']:\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={i}&fields=reviews&language=en&reviews_no_translations=false&key={MY_APY_KEY}\"\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        for j in response.json()['result']['reviews']:\n",
    "            place_reviews['place_id'].append(i)\n",
    "            place_reviews['reviews'].append(j['text'])\n",
    "            place_reviews['reviews_rating'].append(j['rating'])\n",
    "            place_reviews['time'].append(j['time'])\n",
    "        count_yes += 1\n",
    "        print('y', count_yes)\n",
    "    except KeyError:\n",
    "        place_reviews['place_id'].append(i)\n",
    "        place_reviews['reviews'].append('No reviews available')\n",
    "        place_reviews['reviews_rating'].append(np.nan)\n",
    "        place_reviews['time'].append(np.nan)\n",
    "        count_no+=1\n",
    "        print('n', count_no)\n",
    "    if (count_no+count_yes)%100 == 0:\n",
    "        n+=1\n",
    "        to_write = pd.DataFrame(place_reviews)\n",
    "        to_write.to_csv(f'restaurants_reviews{n}.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "place_reviews = pd.DataFrame(place_reviews)\n",
    "place_reviews.to_csv('restaurants_reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get extra details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {\n",
    "    '0': 'sun_hours'\n",
    "    ,'1': 'mon_hours'\n",
    "    ,'2': 'tue_hours'\n",
    "    ,'3': 'wed_hours'\n",
    "    ,'4': 'thu_hours'\n",
    "    ,'5': 'fri_hours'\n",
    "    ,'6': 'sat_hours'\n",
    "\n",
    "}\n",
    "\n",
    "restaurants = pd.read_csv('barc_restaurants.csv')\n",
    "place_details = {'place_id':[], 'dine_in': [], 'reservable': [], 'serves_beer': [], 'serves_wine' :[], 'vegeterian': [], 'takeout': [], 'wheel_chair_acc': [], \n",
    "                 'mon_hours': [], 'tue_hours': [], 'wed_hours': [], 'thu_hours': [], 'fri_hours': [], 'sat_hours': [], 'sun_hours': []}\n",
    "\n",
    "for i in restaurants['place_id']:\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={i}&fields=wheelchair_accessible_entrance%2Cdine_in%2Creservable%2Cserves_vegetarian_food%2Ctakeout%2Cserves_beer%2Cserves_wine%2Copening_hours&key={MY_APY_KEY}\"\n",
    "    response1 = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        response = response1.json()['result']\n",
    "        place_details['place_id'].append(i)\n",
    "        try:\n",
    "            place_details['dine_in'].append(response['dine_in'])\n",
    "        except KeyError:\n",
    "            place_details['dine_in'].append(np.nan)\n",
    "        try:    \n",
    "            place_details['reservable'].append(response['reservable'])\n",
    "        except KeyError:\n",
    "            place_details['reservable'].append(np.nan)\n",
    "        try:\n",
    "            place_details['serves_beer'].append(response['serves_beer'])\n",
    "        except KeyError:\n",
    "            place_details['serves_beer'].append(np.nan)\n",
    "        try:\n",
    "            place_details['serves_wine'].append(response['serves_wine'])\n",
    "        except KeyError:\n",
    "            place_details['serves_wine'].append(np.nan)\n",
    "        try:\n",
    "            place_details['vegeterian'].append(response['serves_vegetarian_food'])\n",
    "        except KeyError:\n",
    "            place_details['vegeterian'].append(np.nan)\n",
    "        try:\n",
    "            place_details['takeout'].append(response['takeout'])\n",
    "        except KeyError:\n",
    "            place_details['takeout'].append(np.nan)\n",
    "        try:\n",
    "            place_details['wheel_chair_acc'].append(response['wheelchair_accessible_entrance'])\n",
    "        except KeyError:\n",
    "            place_details['wheel_chair_acc'].append(np.nan)    \n",
    "        count = 0\n",
    "        try:\n",
    "            a = response['opening_hours']['weekday_text']\n",
    "            for j in response['opening_hours']['weekday_text']:\n",
    "                place_details[days[str(count)]].append(j.split(\": \", 1)[1].replace('\\u202f', '').replace('\\u2009', ''))\n",
    "                count += 1\n",
    "        except:\n",
    "            for j in range(7):\n",
    "                place_details[days[str(j)]].append(np.nan)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "place_details = pd.DataFrame(place_details)\n",
    "place_details.to_csv((f'place_details.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection (schema):\n",
    "    \"\"\"\n",
    "    Creates a connection to a MySQL database using the provided schema, table name, and DataFrame.\n",
    "\n",
    "    Args:\n",
    "        schema (str): The name of the database schema.\n",
    "        table_name (str): The name of the table to connect to.\n",
    "        df (pandas.DataFrame): The DataFrame containing the data to be inserted into the table.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy.engine.Engine: The engine object representing the database connection.\n",
    "    \"\"\"\n",
    "    dbName = schema\n",
    "    password = os.getenv('workbench_pass')\n",
    "    connectionData=f\"mysql+pymysql://root:{password}@localhost/{dbName}\"\n",
    "    engine = alch.create_engine(connectionData)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data_bulky(df, table_name, schema):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to a SQL database table using the specified schema.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame to be uploaded.\n",
    "        table_name (str): The name of the table in the database.\n",
    "        schema (str): The schema of the database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    df.to_sql(con=create_connection(schema), name=table_name, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5023"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_restaurants = pd.read_csv('barc_restaurants.csv')\n",
    "df_restaurants = df.drop(columns=['index'])\n",
    "df_restaurants.to_sql(con=create_connection('search_restaurants'), name='restaurants_details', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24150"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('restaurants_reviews.csv', encoding='latin1')\n",
    "df_reviews = df_reviews.drop(columns=['Unnamed: 0', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'])\n",
    "df_reviews.to_sql(con=create_connection('search_restaurants'), name='restaurants_reviews', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details = pd.read_csv('place_details.csv')\n",
    "df_details = df_details.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "df_details.to_sql(con=create_connection('search_restaurants'), name='restaurants_more_details', if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating hours columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_more_details\"\"\", create_connection('search_restaurants'), index_col='index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to select the restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_reviews\"\"\", create_connection('search_restaurants'), index_col='index')\n",
    "df_details = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_details\"\"\", create_connection('search_restaurants'), index_col='index')\n",
    "df_more_details = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_more_details\"\"\", create_connection('search_restaurants'), index_col='index')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating hours columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_decimal(time_string):\n",
    "    time_object = datetime.strptime(time_string, \"%I:%M%p\")\n",
    "    hour = time_object.hour\n",
    "    minute = time_object.minute\n",
    "    decimal_time = hour + minute / 60.0\n",
    "\n",
    "    return decimal_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_times(my_range):\n",
    "    period_start = my_range.split('–')[0]\n",
    "    period_finish = my_range.split('–')[1]\n",
    "    if period_start[-2:] == 'AM' or period_start[-2:] == 'PM':\n",
    "        pass\n",
    "    else:\n",
    "        period_start += period_finish[-2:]\n",
    " \n",
    "    period_start = convert_time_to_decimal(period_start)\n",
    "    period_finish = convert_time_to_decimal(period_finish)\n",
    "\n",
    "    if period_start > period_finish:\n",
    "        range1 = np.arange(period_start, 24, 0.25)\n",
    "        range2 = np.arange(0, period_finish, 0.25)\n",
    "        range = np.concatenate((range1, range2))\n",
    "    else:\n",
    "        range = np.arange(period_start, period_finish, 0.25)\n",
    "    return range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_times_to_ranges(row):\n",
    "    if row == None:\n",
    "        return np.nan\n",
    "\n",
    "    elif row == 'Closed':\n",
    "        return ['Closed']\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            period_1 = row.split(\",\")[0].strip()\n",
    "            hours_opened = spliting_times(period_1)\n",
    "        except:\n",
    "            return ['Issue']\n",
    "\n",
    "        try:\n",
    "            period_2 = row.split(\",\")[1].strip()\n",
    "            hours_opened_2 = spliting_times(period_2)\n",
    "            hours_opened = np.concatenate((hours_opened, hours_opened_2))\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            period_3 = row.split(\",\")[2].strip()\n",
    "            hours_opened_3 = spliting_times(period_3)\n",
    "            hours_opened = np.concatenate((hours_opened, hours_opened_3))\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "        return hours_opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_more_details.columns[8:]:\n",
    "    df_more_details[i] = df_more_details[i].apply(lambda x: converting_times_to_ranges(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selector function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_details.merge(df_more_details, how='inner', on='place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'place_id', 'business_status', 'raiting', 'price_level',\n",
       "       'total_reviews', 'direction', 'latitud', 'longitud', 'neightbour',\n",
       "       'distritos', 'dine_in', 'reservable', 'serves_beer', 'serves_wine',\n",
       "       'vegeterian', 'takeout', 'wheel_chair_acc', 'mon_hours', 'tue_hours',\n",
       "       'wed_hours', 'thu_hours', 'fri_hours', 'sat_hours', 'sun_hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restaurant_selector(df, raiting=None, min_price=None, max_price=None, total_reviews=None,\n",
    "                        neightbour=None, district=None, dine_in=None, reservable=None,\n",
    "                        serves_beer=None, serves_wine=None, vegetarian=None, takeout=None,\n",
    "                        wheelchair_accessible=None, day=None, time=None):\n",
    "\n",
    "    days = {'Monday': 'mon_hours'\n",
    "            ,'Tuesday': 'tue_hours'\n",
    "            ,'Wednesday': 'wed_hours'\n",
    "            ,'Thursday': 'tue_hours'\n",
    "            ,'Friday': 'fri_hours'\n",
    "            ,'Saturday': 'sat_hours'}\n",
    "    if raiting is not None:\n",
    "        df = df[df['raiting'] >= raiting]\n",
    "    if min_price is not None:\n",
    "        df = df[df['price_level'] >= min_price]\n",
    "    if max_price is not None:\n",
    "        df = df[df['price_level'] <= max_price]\n",
    "    if total_reviews is not None:\n",
    "        df = df[df['total_reviews'] >= total_reviews]\n",
    "    if neightbour is not None:\n",
    "        df = df[df['neightbour'] == neightbour]\n",
    "    if district is not None:\n",
    "        df = df[df['district'] == district]\n",
    "    if dine_in is not None:\n",
    "        df = df[df['dine_in'] == dine_in]\n",
    "    if reservable is not None:\n",
    "        df = df[df['reservable'] == reservable]\n",
    "    if serves_beer is not None:\n",
    "        df = df[df['serves_beer'] == serves_beer]\n",
    "    if serves_wine is not None:\n",
    "        df = df[df['serves_wine'] == serves_wine]\n",
    "    if vegetarian is not None:\n",
    "        df = df[df['vegetarian'] == vegetarian]\n",
    "    if takeout is not None:\n",
    "        df = df[df['takeout'] == takeout]\n",
    "    if wheelchair_accessible is not None:\n",
    "        df = df[df['wheelchair_accessible'] == wheelchair_accessible]\n",
    "    if day is not None:\n",
    "        hours_column = days[day]\n",
    "        df = df[df[hours_column].apply(lambda x: x != ['Closed'] if isinstance(x, list) else True)]\n",
    "    if time is not None:\n",
    "        if day is None:\n",
    "            return KeyError, 'Invalid hour. If an hour is passed, a day must be passed as well'\n",
    "        else:\n",
    "            df = df[time in df[hours_columns]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sat_hours'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = {'Monday': 'mon_hours'\n",
    "            ,'Tuesday': 'tue_hours'\n",
    "            ,'Wednesday': 'wed_hours'\n",
    "            ,'Thursday': 'tue_hours'\n",
    "            ,'Friday': 'fri_hours'\n",
    "            ,'Saturday': 'sat_hours'}\n",
    "\n",
    "days['Saturday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hours_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[298], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m restaurant_selector(df, day\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSaturday\u001b[39;49m\u001b[39m'\u001b[39;49m, time\u001b[39m=\u001b[39;49m\u001b[39m18\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[297], line 45\u001b[0m, in \u001b[0;36mrestaurant_selector\u001b[1;34m(df, raiting, min_price, max_price, total_reviews, neightbour, district, dine_in, reservable, serves_beer, serves_wine, vegetarian, takeout, wheelchair_accessible, day, time)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mKeyError\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mInvalid hour. If an hour is passed, a day must be passed as well\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m         df \u001b[39m=\u001b[39m df[time \u001b[39min\u001b[39;00m df[hours_columns]]\n\u001b[0;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hours_columns' is not defined"
     ]
    }
   ],
   "source": [
    "restaurant_selector(df, day='Saturday', time=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SearchRestaurants",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
