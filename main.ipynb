{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "import time\n",
    "import sqlalchemy as alch\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = pd.read_csv('Barcelona_coordinates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MY_APY_KEY = os.getenv('API_KEY')\n",
    "payload={}\n",
    "headers = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping with Google Maps API"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract all Restaurants in Barcelona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_req(i, radius, API_KEY, total_req):\n",
    "    \"\"\"\n",
    "    Sends a normalized request to the Google Places API to search for nearby restaurants based on the provided location and radius.\n",
    "\n",
    "    Args:\n",
    "        i (str): The location coordinates in the format \"latitude%2Clongitude\".\n",
    "        radius (int): The radius (in meters) within which to search for restaurants.\n",
    "        API_KEY (str): The API key to access the Google Places API.\n",
    "        total_req (int): The total number of requests made so far.\n",
    "\n",
    "    Returns:\n",
    "        requests.Response: The response object containing the result of the API request.\n",
    "    \"\"\"\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json?location={i}&radius={radius}&type=restaurantes&keyword=restaurant&key={API_KEY}\"\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    total_req += 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_page_req(response, APY_KEY, total_req):\n",
    "    \"\"\"\n",
    "    Sends a request to the Google Places API to retrieve the next page of results based on the provided response object. The previous request\n",
    "    can return up to 60 results, organized in 3 pages with 20 results each. If that is the case, the previous request will contain the argument\n",
    "    'next_page_toke'. If not, this argument will not be on the resposne\n",
    "\n",
    "    Args:\n",
    "        response (requests.Response): The response object from the previous API request.\n",
    "        API_KEY (str): The API key to access the Google Places API.\n",
    "        total_req (int): The total number of requests made so far.\n",
    "\n",
    "    Returns:\n",
    "        requests.Response: The response object containing the result of the API request for the next page.\n",
    "    \"\"\"\n",
    "    time.sleep(5)\n",
    "    next_page = response.json()['next_page_token']\n",
    "    url = f'https://maps.googleapis.com/maps/api/place/nearbysearch/json?pagetoken={next_page}&key={APY_KEY}'\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    total_req += 1\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appending_responses(response, business_type, location, name, place_id, raiting, price_level, user_raitings_total, vicinity):\n",
    "    \"\"\"\n",
    "    Extracts specific information from the response object and appends it to the corresponding lists.\n",
    "\n",
    "    Args:\n",
    "        response (requests.Response): The response object from the API request.\n",
    "        business_type (list): The list to store the business status of each result.\n",
    "        location (list): The list to store the location of each result.\n",
    "        name (list): The list to store the name of each result.\n",
    "        place_id (list): The list to store the place ID of each result.\n",
    "        rating (list): The list to store the rating of each result.\n",
    "        price_level (list): The list to store the price level of each result.\n",
    "        user_ratings_total (list): The list to store the total number of user ratings for each result.\n",
    "        vicinity (list): The list to store the vicinity (address or neighborhood) of each result.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the updated lists of business_type, location, name, place_id, rating,\n",
    "               price_level, user_ratings_total, and vicinity.\n",
    "    \"\"\"\n",
    "    for i in response.json()['results']:\n",
    "        try:\n",
    "            business_type.append(i['business_status'])\n",
    "        except KeyError:\n",
    "            business_type.append(np.nan)\n",
    "        try:\n",
    "            location.append(i['geometry']['location'])\n",
    "        except KeyError:\n",
    "            location.append(np.nan)\n",
    "        try:\n",
    "            name.append(i['name'])\n",
    "        except KeyError:\n",
    "            name.append(np.nan)\n",
    "        try:\n",
    "            place_id.append(i['place_id'])\n",
    "        except KeyError:\n",
    "            place_id.append(np.nan)\n",
    "        try:\n",
    "            raiting.append(i['rating'])\n",
    "        except KeyError:\n",
    "            raiting.append(np.nan)\n",
    "        try:\n",
    "            price_level.append(i['price_level'])\n",
    "        except KeyError:\n",
    "            price_level.append(np.nan)\n",
    "        try:\n",
    "            user_raitings_total.append(i['user_ratings_total'])\n",
    "        except KeyError:\n",
    "            user_raitings_total.append(np.nan)\n",
    "        try:\n",
    "            vicinity.append(i['vicinity'])\n",
    "        except:\n",
    "            vicinity.append(np.nan)\n",
    "    return business_type, location, name, place_id, raiting, price_level, user_raitings_total, vicinity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 50\n",
    "total_req = 0\n",
    "\n",
    "business_type = []\n",
    "location = []\n",
    "name = []\n",
    "place_id = []\n",
    "raiting = []\n",
    "price_level = []\n",
    "user_raitings_total = []\n",
    "vicinity = []\n",
    "total_req = 0\n",
    "\n",
    "for j in coordinates.columns[:1]:\n",
    "    for i in coordinates[j][:2]:\n",
    "        response = norm_req(i, radius, MY_APY_KEY, total_req)\n",
    "        appending_responses(response)\n",
    "        try:\n",
    "            response = next_page_req(response, MY_APY_KEY, total_req)\n",
    "            appending_responses(response)\n",
    "            try:\n",
    "                response = next_page_req(response, MY_APY_KEY, total_req)\n",
    "                appending_responses(response)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {\n",
    "    'name': name,\n",
    "    'place_id': place_id,\n",
    "    'business_status': business_type,\n",
    "    'location': location,\n",
    "    'raiting': raiting,\n",
    "    'price_level': price_level,\n",
    "    'total_reviews': user_raitings_total,\n",
    "    'direction': vicinity\n",
    "}\n",
    "my_data = pd.DataFrame(my_data)\n",
    "\n",
    "my_data = my_data.drop_duplicates(subset=['place_id', 'location']) # Dropping same restaurant in case I scrapped twice\n",
    "my_data['latitud'] = my_data['location'].apply(lambda x: x.split(\",\")[0].split(\":\")[1].strip()) #Isolating the latitud\n",
    "my_data['longitud'] = my_data['location'].apply(lambda x: x.split(\",\")[1].split(\":\")[1].strip()[:-1]) #Isolating the longitud\n",
    "my_data.drop(columns='location', inplace=True)\n",
    "\n",
    "my_data.to_csv('barc_restaurants.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting the neightbourhood of each restaurant (using Mongo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client[\"Search_Restaurants\"]\n",
    "df_distritos = db.get_collection(\"Distritos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost:27017\")\n",
    "db = client[\"Search_Restaurants\"]\n",
    "df_barrios = db.get_collection(\"Neightbours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barrios(df, long, lat):\n",
    "    \"\"\"\n",
    "    Retrieves the name of the neighborhood (barrio) that intersects with the specified coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - lat (float): Latitude of the location.\n",
    "    - long (float): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    - str: The name of the neighborhood (barrio) that intersects with the specified coordinates.\n",
    "           If no intersection is found, it returns \"Not found\".\n",
    "    \"\"\"\n",
    "    my_position = {\"type\": \"Point\", \"coordinates\": [long, lat]} # o al revés\n",
    "\n",
    "    result = df.find_one(\n",
    "            {\"geometry\": \n",
    "                    {\"$geoIntersects\": \n",
    "                        {\"$geometry\": my_position}}\n",
    "            })\n",
    "    try:\n",
    "        return result[\"properties\"][\"NOM\"]\n",
    "    except:\n",
    "        return \"Not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data['neightbour'] = my_data.apply(lambda row: get_barrios(df_barrios, row['longitud'], row['latitud']), axis=1)\n",
    "my_data['distritos'] = my_data.apply(lambda row: get_barrios(df_distritos, row['longitud'], row['latitud']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.to_csv('barc_restaurants.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reviews details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = pd.read_csv('barc_restaurants.csv')\n",
    "place_reviews = {'place_id':[], 'reviews': [], 'reviews_rating': [], 'time': []}\n",
    "\n",
    "count_yes = 0\n",
    "count_no = 0\n",
    "n = 0\n",
    "for i in restaurants['place_id']:\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={i}&fields=reviews&language=en&reviews_no_translations=false&key={MY_APY_KEY}\"\n",
    "    response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        for j in response.json()['result']['reviews']:\n",
    "            place_reviews['place_id'].append(i)\n",
    "            place_reviews['reviews'].append(j['text'])\n",
    "            place_reviews['reviews_rating'].append(j['rating'])\n",
    "            place_reviews['time'].append(j['time'])\n",
    "        count_yes += 1\n",
    "        print('y', count_yes)\n",
    "    except KeyError:\n",
    "        place_reviews['place_id'].append(i)\n",
    "        place_reviews['reviews'].append('No reviews available')\n",
    "        place_reviews['reviews_rating'].append(np.nan)\n",
    "        place_reviews['time'].append(np.nan)\n",
    "        count_no+=1\n",
    "        print('n', count_no)\n",
    "    if (count_no+count_yes)%100 == 0:\n",
    "        n+=1\n",
    "        to_write = pd.DataFrame(place_reviews)\n",
    "        to_write.to_csv(f'restaurants_reviews{n}.csv')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "place_reviews = pd.DataFrame(place_reviews)\n",
    "place_reviews.to_csv('restaurants_reviews.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get extra details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = {\n",
    "    '0': 'sun_hours'\n",
    "    ,'1': 'mon_hours'\n",
    "    ,'2': 'tue_hours'\n",
    "    ,'3': 'wed_hours'\n",
    "    ,'4': 'thu_hours'\n",
    "    ,'5': 'fri_hours'\n",
    "    ,'6': 'sat_hours'\n",
    "\n",
    "}\n",
    "\n",
    "restaurants = pd.read_csv('barc_restaurants.csv')\n",
    "place_details = {'place_id':[], 'dine_in': [], 'reservable': [], 'serves_beer': [], 'serves_wine' :[], 'vegeterian': [], 'takeout': [], 'wheel_chair_acc': [], \n",
    "                 'mon_hours': [], 'tue_hours': [], 'wed_hours': [], 'thu_hours': [], 'fri_hours': [], 'sat_hours': [], 'sun_hours': []}\n",
    "\n",
    "for i in restaurants['place_id']:\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={i}&fields=wheelchair_accessible_entrance%2Cdine_in%2Creservable%2Cserves_vegetarian_food%2Ctakeout%2Cserves_beer%2Cserves_wine%2Copening_hours&key={MY_APY_KEY}\"\n",
    "    response1 = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "    try:\n",
    "        response = response1.json()['result']\n",
    "        place_details['place_id'].append(i)\n",
    "        try:\n",
    "            place_details['dine_in'].append(response['dine_in'])\n",
    "        except KeyError:\n",
    "            place_details['dine_in'].append(np.nan)\n",
    "        try:    \n",
    "            place_details['reservable'].append(response['reservable'])\n",
    "        except KeyError:\n",
    "            place_details['reservable'].append(np.nan)\n",
    "        try:\n",
    "            place_details['serves_beer'].append(response['serves_beer'])\n",
    "        except KeyError:\n",
    "            place_details['serves_beer'].append(np.nan)\n",
    "        try:\n",
    "            place_details['serves_wine'].append(response['serves_wine'])\n",
    "        except KeyError:\n",
    "            place_details['serves_wine'].append(np.nan)\n",
    "        try:\n",
    "            place_details['vegeterian'].append(response['serves_vegetarian_food'])\n",
    "        except KeyError:\n",
    "            place_details['vegeterian'].append(np.nan)\n",
    "        try:\n",
    "            place_details['takeout'].append(response['takeout'])\n",
    "        except KeyError:\n",
    "            place_details['takeout'].append(np.nan)\n",
    "        try:\n",
    "            place_details['wheel_chair_acc'].append(response['wheelchair_accessible_entrance'])\n",
    "        except KeyError:\n",
    "            place_details['wheel_chair_acc'].append(np.nan)    \n",
    "        count = 0\n",
    "        try:\n",
    "            a = response['opening_hours']['weekday_text']\n",
    "            for j in response['opening_hours']['weekday_text']:\n",
    "                place_details[days[str(count)]].append(j.split(\": \", 1)[1].replace('\\u202f', '').replace('\\u2009', ''))\n",
    "                count += 1\n",
    "        except:\n",
    "            for j in range(7):\n",
    "                place_details[days[str(j)]].append(np.nan)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "place_details = pd.DataFrame(place_details)\n",
    "place_details.to_csv((f'place_details.csv'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection (schema):\n",
    "    \"\"\"\n",
    "    Creates a connection to a MySQL database using the provided schema, table name, and DataFrame.\n",
    "\n",
    "    Args:\n",
    "        schema (str): The name of the database schema.\n",
    "        table_name (str): The name of the table to connect to.\n",
    "        df (pandas.DataFrame): The DataFrame containing the data to be inserted into the table.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy.engine.Engine: The engine object representing the database connection.\n",
    "    \"\"\"\n",
    "    dbName = schema\n",
    "    password = os.getenv('workbench_pass')\n",
    "    connectionData=f\"mysql+pymysql://root:{password}@localhost/{dbName}\"\n",
    "    engine = alch.create_engine(connectionData)\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_data_bulky(df, table_name, schema):\n",
    "    \"\"\"\n",
    "    Uploads a DataFrame to a SQL database table using the specified schema.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame to be uploaded.\n",
    "        table_name (str): The name of the table in the database.\n",
    "        schema (str): The schema of the database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    df.to_sql(con=create_connection(schema), name=table_name, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5023"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('barc_restaurants.csv')\n",
    "df = df.drop(columns=['index'])\n",
    "df.to_sql(con=create_connection('search_restaurants'), name='restaurants_details', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24150"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('restaurants_reviews.csv', encoding='latin1')\n",
    "df_reviews = df_reviews.drop(columns=['Unnamed: 0', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'])\n",
    "df_reviews.to_sql(con=create_connection('search_restaurants'), name='restaurants_reviews', if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details = pd.read_csv('place_details.csv')\n",
    "df_details = df_details.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])\n",
    "df_details.to_sql(con=create_connection('search_restaurants'), name='restaurants_more_details', if_exists='replace')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating hours columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_more_details\"\"\", create_connection('search_restaurants'), index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_to_decimal(time_string):\n",
    "    time_object = datetime.strptime(time_string, \"%I:%M%p\")\n",
    "    hour = time_object.hour\n",
    "    minute = time_object.minute\n",
    "    decimal_time = hour + minute / 60.0\n",
    "\n",
    "    return decimal_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spliting_times(my_range):\n",
    "    period_start = my_range.split('–')[0]\n",
    "    period_finish = my_range.split('–')[1]\n",
    "    if period_start[-2:] == 'AM' or period_start[-2:] == 'PM':\n",
    "        pass\n",
    "    else:\n",
    "        period_start += period_finish[-2:]\n",
    " \n",
    "    period_start = convert_time_to_decimal(period_start)\n",
    "    period_finish = convert_time_to_decimal(period_finish)\n",
    "\n",
    "    if period_start > period_finish:\n",
    "        range1 = np.arange(period_start, 24, 0.25)\n",
    "        range2 = np.arange(0, period_finish, 0.25)\n",
    "        range = np.concatenate((range1, range2))\n",
    "    else:\n",
    "        range = np.arange(period_start, period_finish, 0.25)\n",
    "    return range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_times_to_ranges(row):\n",
    "    if row == None:\n",
    "        return np.nan\n",
    "\n",
    "    elif row == 'Closed':\n",
    "        return ['Closed']\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            period_1 = row.split(\",\")[0].strip()\n",
    "            hours_opened = spliting_times(period_1)\n",
    "        except:\n",
    "            return ['Issue']\n",
    "\n",
    "        try:\n",
    "            period_2 = row.split(\",\")[1].strip()\n",
    "            hours_opened_2 = spliting_times(period_2)\n",
    "            hours_opened = np.concatenate((hours_opened, hours_opened_2))\n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            period_3 = row.split(\",\")[2].strip()\n",
    "            hours_opened_3 = spliting_times(period_3)\n",
    "            hours_opened = np.concatenate((hours_opened, hours_opened_3))\n",
    "        except IndexError:\n",
    "            pass\n",
    "\n",
    "        return hours_opened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_details.columns[8:]:\n",
    "    df_details[i] = df_details[i].apply(lambda x: converting_times_to_ranges(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = pd.read_sql_query(\"\"\"\n",
    "SELECT * FROM restaurants_reviews\"\"\", create_connection('search_restaurants'), index_col='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "place_id           object\n",
       "reviews            object\n",
       "reviews_rating    float64\n",
       "time              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SearchRestaurants",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
